{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 6407 Скосырский Никита. Вариант 3. Лабораторная работа 1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Классификация данных методом k ближайших соседей ( kNN)\n",
    "\n",
    "2) Классификация данных методом опорных векторов (SVM)\n",
    "\n",
    "3) Построение softmax-классификатора\n",
    "\n",
    "Вариант 1: задания 1 и 2 на наборе данных CIFAR-10\n",
    "\n",
    "Вариант 2: задания 1 и 2 на наборе данных MNIST\n",
    "\n",
    "Вариант 3: задания 1 и 3 на наборе данных CIFAR-10\n",
    "\n",
    "Вариант 4: задания 1 и 3 на наборе данных MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторные работы можно выполнять с использованием сервиса Google Colaboratory (https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) или на локальном компьютере. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Классификация данных методом k ближайших соседей ( kNN)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:18.404731Z",
     "start_time": "2024-05-04T10:55:15.564750Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install imageio\n",
    "from scripts.data_utils import load_CIFAR10\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Скачайте данные в соответсвии с заданием.\n",
    "\n",
    "CIFAR-10 по ссылке https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "или используйте  команду !bash get_datasets.sh (google colab, local ubuntu)\n",
    "\n",
    "MNIST \n",
    "sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:21.519601Z",
     "start_time": "2024-05-04T10:55:21.491874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:24.650972Z",
     "start_time": "2024-05-04T10:55:23.694481Z"
    }
   },
   "source": [
    "cifar10_dir = 'scripts/datasets/cifar-10-batches-py'\n",
    "\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Выведите несколько примеров изображений из обучающей выборки для каждого класса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:28.942859Z",
     "start_time": "2024-05-04T10:55:27.333712Z"
    }
   },
   "source": [
    "# Зададим количество изображений для вывода для каждого класса\n",
    "num_classes = 10\n",
    "samples_per_class = 7\n",
    "\n",
    "# Создадим функцию для визуализации\n",
    "def visualize_cifar10_samples(X, y, classes, samples_per_class):\n",
    "    for y_cls, cls in enumerate(classes):\n",
    "        # Индексы изображений текущего класса\n",
    "        idxs = np.flatnonzero(y == y_cls)\n",
    "        # Выберем случайные изображения\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            # Настроим подграфику для вывода изображений\n",
    "            plt_idx = i * num_classes + y_cls + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(X[idx].astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "\n",
    "# Зададим названия классов CIFAR-10 (по порядку)\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Выведем изображения\n",
    "plt.figure(figsize=(samples_per_class*num_classes, 8))\n",
    "visualize_cifar10_samples(X_train, y_train, classes, samples_per_class)\n",
    "plt.show()"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Разделите данные на обучающу и тестовую выборки (X_train, y_train, X_test, y_test). Преобразуйте каждое изображение в одномерный массив. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:32.385832Z",
     "start_time": "2024-05-04T10:55:31.687338Z"
    }
   },
   "source": [
    "# Преобразуем обучающие данные\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1) # X_train.shape[0] это количество примеров\n",
    "\n",
    "# Преобразуем тестовые данные\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1) # X_test.shape[0] это количество примеров\n",
    "\n",
    "print('Training data shape after flattening: ', X_train_flat.shape)\n",
    "print('Test data shape after flattening: ', X_test_flat.shape)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Напишите реализацию классификатора в скрипте /classifiers/k_nearest_neighbor.py и обучите его на сформированной выборке. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:34.830784Z",
     "start_time": "2024-05-04T10:55:34.813442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib import reload\n",
    "from scripts.classifiers import k_nearest_neighbor\n",
    "\n",
    "# Перезагрузка модуля k_nearest_neighbor\n",
    "reload(k_nearest_neighbor)\n",
    "\n",
    "# Импорт функции KNearestNeighbor после перезагрузки модуля\n",
    "from scripts.classifiers import KNearestNeighbor"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:55:37.352853Z",
     "start_time": "2024-05-04T10:55:37.346489Z"
    }
   },
   "source": [
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train_flat, y_train)"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Выполните классификацию на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:57:01.587781Z",
     "start_time": "2024-05-04T10:55:40.398552Z"
    }
   },
   "source": [
    "k = 5\n",
    "\n",
    "# Выполняем классификацию на тестовой выборке\n",
    "y_test_pred = classifier.predict(X_test_flat, k=k, num_loops=0) # num_loops=0 для векторизованного расчета\n",
    "\n",
    "# Теперь y_test_pred содержит предсказанные метки для тестовой выборки"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Визуализируйте матрицу расстояний для каждого изображения из тестовой выборки до изображений из обучающей выборки. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:57:47.992100Z",
     "start_time": "2024-05-04T10:57:08.406644Z"
    }
   },
   "source": [
    "# Вычисление матрицы расстояний между тестовыми и обучающими данными\n",
    "dists = classifier.compute_distances_no_loops(X_test_flat)\n",
    "\n",
    "# Визуализация матрицы расстояний: каждая строка относится к тестовому изображению,\n",
    "# а каждый столбец - к обучающему изображению\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.xlabel('Training images')\n",
    "plt.ylabel('Test images')\n",
    "plt.title('Distance matrix')\n",
    "plt.show()"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.7 Посчитайте долю правильно классифицированных изображений из тестовой выборки.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T10:58:14.249513Z",
     "start_time": "2024-05-04T10:58:14.204704Z"
    }
   },
   "source": [
    "# Считаем количество правильных предсказаний\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "\n",
    "# Считаем долю правильных предсказаний (точность)\n",
    "accuracy = float(num_correct) / len(y_test)\n",
    "\n",
    "print('Правильно классифицированных изображений: %d из %d' % (num_correct, len(y_test)))\n",
    "print('Точность: %f' % accuracy)"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8 Постройте график зависимости доли правильно классифицированных изображений от числа соседей, используемых при классификации."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:11:04.784788Z",
     "start_time": "2024-05-04T10:58:46.241967Z"
    }
   },
   "source": [
    "k_values = list(range(5, 56, 5))  # начинаем с 5, заканчиваем 55, шаг 5\n",
    "accuracies = []\n",
    "\n",
    "# Размер пакета для обработки тестовых данных\n",
    "batch_size = 5000\n",
    "\n",
    "for k in k_values:\n",
    "    num_correct = 0\n",
    "    for i in range(0, len(y_test), batch_size):\n",
    "        # Обработка тестовых данных пакетами\n",
    "        X_test_batch = X_test_flat[i:i + batch_size]\n",
    "        y_test_batch = y_test[i:i + batch_size]\n",
    "\n",
    "        # Предсказание меток для текущего пакета\n",
    "        y_test_batch_pred = classifier.predict(X_test_batch, k=k, num_loops=0)\n",
    "\n",
    "        # Считаем количество правильных предсказаний в текущем пакете\n",
    "        num_correct += np.sum(y_test_batch_pred == y_test_batch)\n",
    "\n",
    "    # Расчет точности для текущего значения k\n",
    "    accuracy = float(num_correct) / len(y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print('k = %d, accuracy = %f' % (k, accuracy))\n",
    "\n",
    "# Построение графика\n",
    "plt.plot(k_values, accuracies)\n",
    "plt.xlabel('Number of neighbors k')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.title('k-NN varying number of neighbors')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.9 Выберите лучшее значение параметра k на основе кросс-валидации.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T11:11:04.818832Z",
     "start_time": "2024-05-04T11:11:04.784788Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import KFold",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:17:25.830862Z",
     "start_time": "2024-05-04T11:11:04.818832Z"
    }
   },
   "source": [
    "k_values = list(range(6, 35, 2))  # define the list of k values\n",
    "\n",
    "# Создаем объект KFold для кросс-валидации\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Создаем список для хранения значений точности для каждого значения k\n",
    "accuracies = []\n",
    "\n",
    "# Итерируемся по значениям k\n",
    "for k in k_values:\n",
    "    # Создаем список для хранения значений точности для каждого фолда\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Итерируемся по фолдам\n",
    "    for train_index, val_index in k_fold.split(X_train_flat):\n",
    "        # Разделяем данные на обучающую и валидационную выборки\n",
    "        X_train_fold = X_train_flat[train_index]\n",
    "        y_train_fold = y_train[train_index]\n",
    "        X_val_fold = X_train_flat[val_index]\n",
    "        y_val_fold = y_train[val_index]\n",
    "\n",
    "        # Обучаем модель на текущем фолде\n",
    "        classifier.train(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Оцениваем модель на валидационной выборке\n",
    "        y_val_pred = classifier.predict(X_val_fold, k=k, num_loops=0)\n",
    "        accuracy = np.mean(y_val_pred == y_val_fold)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    # Оцениваем среднюю точность для текущего значения k\n",
    "    accuracy = np.mean(fold_accuracies)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Выбираем лучшее значение k на основе средней точности\n",
    "best_k = k_values[np.argmax(accuracies)]\n",
    "\n",
    "print('Лучшее значение k:', best_k)\n",
    "print('Средняя точность:', np.max(accuracies))"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.10 Переобучите и протестируйте классификатор с использованием выбранного значения k.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:18:38.107710Z",
     "start_time": "2024-05-04T12:17:25.846492Z"
    }
   },
   "source": [
    "# Переобучаем классификатор с использованием лучшего значения k\n",
    "classifier.train(X_train_flat, y_train)\n",
    "\n",
    "# Тестируем классификатор на тестовой выборке\n",
    "y_test_pred = classifier.predict(X_test_flat, k=best_k, num_loops=0)\n",
    "\n",
    "# Оцениваем качество классификации\n",
    "accuracy = np.mean(y_test_pred == y_test)\n",
    "print('Точность классификации:', accuracy)"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.11 Сделайте выводы по результатам 1 части задания."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Точность классификации: 0.34\n",
    "\n",
    "*Я считаю - это отличная точность при такой простой архитектуре.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Классификация данных методом опорных векторов (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Разделите данные на обучающую, тестовую и валидационную выборки. Преобразуйте каждое изображение в одномерный массив. Выведите размеры выборок."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Проведите предварительную обработку данных, путем вычитания среднего изображения, рассчитанного  по обучающей выборке.\n",
    "\n",
    "2.3 Чтобы далее не учитывать смещение (свободный член b), добавьте дополнитульную размерность к массиву дынных и заполните ее 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mean_image = np.mean(X_train, axis=0)\n",
    "print(mean_image[:10]) \n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) \n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Реализуйте loss-функции в scripts/classifiers/linear_svm.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "from scripts.classifiers.linear_svm import svm_loss_naive\n",
    "import time\n",
    "\n",
    "\n",
    "W = np.random.randn(3073, 10) * 0.0001 \n",
    "\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "print('loss: %f' % (loss, ))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2.5 Убедитесь, что вы верно реализовали расчет градиента, сравнив с реализацией численными методами (код приведен ниже)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "from scripts.gradient_check import grad_check_sparse\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)\n",
    "\n",
    "\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Сравните svm_loss_naive и svm_loss_vectorized реализации"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tic = time.time()\n",
    "_, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Naive loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('Vectorized loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('difference: %f' % difference)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Реализуйте стохастический градиентный спуск в /classifiers/linear_classifier.py . Реализуйте методы train() и predict() и запустите следующий код"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scripts.classifiers import LinearSVM\n",
    "svm = LinearSVM()\n",
    "tic = time.time()\n",
    "loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
    "                      num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_train_pred = svm.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_val_pred = svm.predict(X_val)\n",
    "print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8 С помощью кросс-валидации выберите значения параметров скорости обучения и регуляризации. В кросс-валидации используйте обучающую и валидационную выборки. Оцените accuracy на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "learning_rates = [1e-7, 5e-5]\n",
    "regularization_strengths = [2.5e4, 5e4]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9 Сделайте выводы по второй части задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Построение softmax-классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Разделите данные на обучающую, тестовую и валидационную выборки. Преобразуйте каждое изображение в одномерный массив. Выведите размеры выборок."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:35:22.306932Z",
     "start_time": "2024-05-04T13:35:21.460830Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение данных на обучающую и валидационную выборки\n",
    "softmax_X_train, softmax_X_val, softmax_y_train, softmax_y_val = train_test_split(X_train_flat, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Разделение данных на тестовую и валидационную выборки\n",
    "softmax_X_val, softmax_X_test, softmax_y_val, softmax_y_test = train_test_split(softmax_X_val, softmax_y_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# Вывод размеров выборок\n",
    "print('Training set:', softmax_X_train.shape, softmax_y_train.shape)\n",
    "print('Validation set:', softmax_X_val.shape, softmax_y_val.shape)\n",
    "print('Test set:', softmax_X_test.shape, softmax_y_test.shape)"
   ],
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Проведите предварительную обработку данных, путем вычитания среднего изображения, рассчитанного  по обучающей выборке.\n",
    "\n",
    "3.3 Чтобы далее не учитывать смещение (свободный член b), добавьте дополнительную размерность к массиву данных и заполните ее единицами."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:35:24.478579Z",
     "start_time": "2024-05-04T13:35:24.242295Z"
    }
   },
   "source": [
    "# 3.2 Общий способ центрирования данных и уменьшения влияния изменений освещения\n",
    "mean_image = np.mean(softmax_X_train, axis=0)\n",
    "softmax_X_train -= mean_image\n",
    "softmax_X_val -= mean_image\n",
    "softmax_X_test -= mean_image"
   ],
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:35:26.472885Z",
     "start_time": "2024-05-04T13:35:25.873567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3.3\n",
    "softmax_X_train = np.hstack((softmax_X_train, np.ones((softmax_X_train.shape[0], 1))))\n",
    "softmax_X_val = np.hstack((softmax_X_val, np.ones((softmax_X_val.shape[0], 1))))\n",
    "softmax_X_test = np.hstack((softmax_X_test, np.ones((softmax_X_test.shape[0], 1))))\n",
    "\n",
    "print(mean_image[:10])  # выводим первые 10 элементов среднего изображения\n",
    "\n",
    "# визуализируем среднее изображение\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(mean_image.reshape((32, 32, 3)).astype('uint8'))\n",
    "plt.show()"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Реализуйте функции в classifiers/softmax.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:35:28.969573Z",
     "start_time": "2024-05-04T13:35:28.954257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from importlib import reload\n",
    "from scripts.classifiers import softmax\n",
    "\n",
    "# Перезагрузка модуля softmax\n",
    "reload(softmax)\n",
    "\n",
    "# Импорт функции softmax_loss_naive после перезагрузки модуля\n",
    "from scripts.classifiers.softmax import softmax_loss_naive\n",
    "from scripts.classifiers.softmax import softmax_loss_vectorized\n",
    "import time"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:35:31.269734Z",
     "start_time": "2024-05-04T13:35:29.570029Z"
    }
   },
   "source": [
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, softmax_X_val, softmax_y_val, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)    \n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Убедитесь, что вы верно реализовали расчет градиента, сравнив с реализацией численными методами (код приведен ниже)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:36:37.749383Z",
     "start_time": "2024-05-04T13:35:33.839242Z"
    }
   },
   "source": [
    "# Check the gradient using numerical methods\n",
    "loss, grad = softmax_loss_naive(W, softmax_X_val, softmax_y_val, 0.0)\n",
    "\n",
    "from scripts.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, softmax_X_val, softmax_y_val, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "print('Gradient difference:', grad_numerical)\n",
    "\n",
    "loss, grad = softmax_loss_naive(W, softmax_X_val, softmax_y_val, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, softmax_X_val, softmax_y_val, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "print('Gradient difference:', grad_numerical)"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Сравните softmax_loss_naive и softmax_loss_vectorized реализации"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T13:36:50.932715Z",
     "start_time": "2024-05-04T13:36:49.173778Z"
    }
   },
   "source": [
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, softmax_X_val, softmax_y_val, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, softmax_X_val, softmax_y_val, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Реализуйте стохастический градиентный спуск в /classifiers/linear_classifier.py . Реализуйте методы train() и predict() и запустите следующий код.\n",
    "\n",
    "3.8 Обучите Softmax-классификатор и оцените accuracy на тестовой выборке."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T14:22:36.318355Z",
     "start_time": "2024-05-04T14:22:36.303385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# следующий код не был обнаружен, потому был написан\n",
    "from importlib import reload\n",
    "from scripts.classifiers import linear_classifier\n",
    "from scripts.classifiers import linear_svm\n",
    "from scripts.classifiers import softmax\n",
    "\n",
    "# Перезагрузка модуля linear_classifier\n",
    "reload(linear_classifier)\n",
    "reload(linear_svm)\n",
    "reload(softmax)\n",
    "\n",
    "from scripts.classifiers.linear_classifier import LinearSVM\n",
    "from scripts.classifiers.linear_classifier import Softmax"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T14:33:21.400319Z",
     "start_time": "2024-05-04T14:33:12.317376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаем объекты классификаторов\n",
    "svm = LinearSVM()\n",
    "softmax_classifier = Softmax()\n",
    "\n",
    "# Обучаем модели\n",
    "svm.train(softmax_X_train, softmax_y_train, learning_rate=1e-7, reg=2.5e4, num_iters=1500, verbose=True)\n",
    "softmax_classifier.train(softmax_X_train, softmax_y_train, learning_rate=1e-7, reg=2.5e4, num_iters=1500, verbose=True)\n",
    "\n",
    "# Оцениваем точность на тестовой выборке\n",
    "y_test_pred_svm = svm.predict(softmax_X_test)\n",
    "y_test_pred_softmax = softmax_classifier.predict(softmax_X_test)\n",
    "accuracy_svm = np.mean(y_test_pred_svm == softmax_y_test)\n",
    "accuracy_softmax = np.mean(y_test_pred_softmax == softmax_y_test)\n",
    "\n",
    "print('SVM accuracy: %f' % accuracy_svm)\n",
    "print('Softmax accuracy: %f' % accuracy_softmax)"
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.9 С помощью кросс-валидации выберите значения параметров скорости обучения и регуляризации. В кросс-валидации используйте обучающую и валидационную выборки. Оцените accuracy на тестовой выборке."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# learning_rates = [1e-7, 5e-5]\n",
    "# regularization_strengths = [2.5e4, 5e4]"
   ],
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:14:31.991793Z",
     "start_time": "2024-05-04T15:14:31.975266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scripts.classifiers import softmax\n",
    "\n",
    "# Перезагрузка модуля softmax\n",
    "reload(softmax)\n",
    "\n",
    "# Импорт функции softmax_loss_vectorized после перезагрузки модуля\n",
    "from scripts.classifiers.softmax import softmax_loss_vectorized\n"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:16:05.893835Z",
     "start_time": "2024-05-04T15:15:40.846623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Заданные диапазоны для скорости обучения и регуляризации с учетом предложенных изменений\n",
    "learning_rates = [1e-7, 3e-7, 1e-6]\n",
    "regularization_strengths = [1e4, 2.5e4]\n",
    "\n",
    "# Словарь для хранения результатов\n",
    "results = {}\n",
    "best_val = -1   # Начальное значение лучшей точности\n",
    "best_softmax = None  # Лучшая модель softmax\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        softmax = Softmax()\n",
    "        softmax.train(softmax_X_train, softmax_y_train, learning_rate=lr, reg=reg, num_iters=1500, verbose=True)\n",
    "\n",
    "        y_train_pred = softmax.predict(softmax_X_train)\n",
    "        y_val_pred = softmax.predict(softmax_X_val)\n",
    "\n",
    "        train_accuracy = np.mean(y_train_pred == softmax_y_train)\n",
    "        val_accuracy = np.mean(y_val_pred == softmax_y_val)\n",
    "\n",
    "        results[(lr, reg)] = (train_accuracy, val_accuracy)\n",
    "\n",
    "        # Обновление лучшей модели\n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = softmax\n",
    "\n",
    "# Вывод результатов\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "        lr, reg, train_accuracy, val_accuracy))\n",
    "\n",
    "print('\\nbest validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "# Тестирование лучшей модели\n",
    "y_test_pred = best_softmax.predict(softmax_X_test)\n",
    "test_accuracy = np.mean(y_test_pred == softmax_y_test)\n",
    "print('Test accuracy: %f' % test_accuracy)"
   ],
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.10 Сделайте выводы по третьей части задания"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В третьей части задания мы успешно реализовали и оптимизировали softmax-классификатор для набора данных CIFAR-10. Основные шаги включали:\n",
    "\n",
    "1. **Предобработку данных:** Центрирование данных путем вычитания среднего изображения.\n",
    "2. **Реализация функций потерь:** Эффективная векторизованная реализация показала значительное преимущество по времени выполнения по сравнению с наивной реализацией.\n",
    "3. **Обучение и кросс-валидация:** Оптимизация параметров с помощью кросс-валидации выявила оптимальные значения скорости обучения и силы регуляризации.\n",
    "4. **Тестирование модели:** Проверка на тестовом наборе данных показала адекватную точность, подтверждая правильность подхода и эффективность модели.\n",
    "5. **Эффективность модели:** Показатель точности около 35% может показаться не очень высоким, но для многоклассовой классификации на CIFAR-10 без сложных архитектур нейронных сетей это довольно хороший результат. CIFAR-10 - сложная задача с 10 классами, где даже небольшое улучшение точности может требовать значительных усилий.\n",
    "\n",
    "**Результаты:** Модель достигла приемлемой точности на тестовой выборке, что подтверждает корректность выбранных параметров и методов обучения. Проблемы численной стабильности были решены через корректировки в реализации функции потерь и настройках гиперпараметров.\n",
    "\n",
    "Вывод: Применение векторизации, адекватная предобработка данных и точная настройка гиперпараметров способствуют созданию эффективных и стабильных моделей машинного обучения.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
